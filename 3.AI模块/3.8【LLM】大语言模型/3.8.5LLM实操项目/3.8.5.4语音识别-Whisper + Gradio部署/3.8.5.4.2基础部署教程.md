# Extra. Whisper + Gradio 的简单部署

## 虚拟环境的准备

首先我们要准备一个虚拟环境，你也不想 whisper 和 gradio 的一大堆依赖把你的环境给污染了罢（）

注意这里用的是原版 Python，与 Anaconda 什么的可能在操作上存在区别，以实际为准。

### 创建虚拟环境

新建一个文件夹然后在终端中打开，然后输入：

```shell
python -m venv .\.venv
```

或者，可以在 vscode 打开对应文件夹后按 `ctrl+shift+p` 之后选择 `Python: 创建虚拟环境` -> `Venv` -> 选择你需要的 Python 版本。

如果不出意外的话，等待一会儿虚拟环境就创建好了，目录下会多一个叫 `.venv` 的文件夹。

### 激活虚拟环境

如果是在 vscode 中，做完上述操作之后虚拟环境会自动激活；如果是手动创建的话，需要执行：

```shell
.\.venv\Scripts\activate
```

来激活虚拟环境。

如果手动激活失败的话把 `activate` 换成 `Activate.ps1` 或 `activate.bat` 试试。

激活后最左边会出现绿色的 `(.venv)` 字样（虚拟环境的名字）（不过在 vscode 的终端中可能不会出现）。

在 powershell 中可以使用 `Get-Command python` 来检查虚拟环境的激活状态，如果激活的话 `Source` 值应该为虚拟环境下的解释器路径。

### 安装依赖

接下来就可以安装必要的依赖们了。

#### 安装 whisper

如果不出意外的话，直接跟着 whisper 的 README 文档安装就可以了。

在激活虚拟环境的终端中使用 pip 安装：

```shell
pip install -U openai-whisper
```

稍等一下应该就行了。

下载速度慢的话可以换个源再试，我个人用的是清华大学源。换源的教程请自己去找资料罢（

把 ffmpeg 也安装完成之后在虚拟环境下可以直接使用 `whisper` 命令进行调用。

可能会出现不认 cuda 的情况，但是由于 whisper 自带的很多模型都很轻量所以 cpu 也能跑，这里就直接带过了。

#### 安装 ffmpeg

为了让 whisper 能够处理各种格式的音频，我们还需要安装 ffmpeg。

为了检查是否已经安装过 ffmpeg，在终端中输入：

```shell
ffmpeg -h
```

如果输出了一大堆东西（ffmpeg 的使用说明），说明已经装好了就不用再装了。

如果提示未找到指令的话说明没装呢。去这里下载一个，解压之后放到一个路径不含非英文字符的文件夹里，然后把 ffmpeg 的路径添加到 PATH 里。（可以去读这个或者网上找教程，或者继续看我写的垃圾）

要把 ffmpeg 添加到 PATH：

1. 找到 ffmpeg.exe 究竟在哪（直接解压的话应该会在 bin 文件夹里），然后复制它所在的文件夹的路径。
2. 右键此电脑 -> 属性 -> 高级系统设置（或者直接在开始菜单搜高级系统设置） -> 环境变量，在系统变量一栏里找到 Path 双击打开。
3. 新建一个项把你先前复制的路径粘进去然后保存就好了。
4. 按上面的方法检查是否安装成功。

#### 安装 gradio

根据 gradio 官方文档，使用 pip 安装：

```shell
pip install gradio
```

应该就能安装完成了。

要检验 gradio 的安装，正确做法是在 Python Shell 里尝试 `import gradio`，而不是直接在命令行打 gradio 

没错就很简单啊，真开箱即用啊。

如果出现了各种问题的话就 Google 启动罢。不过我真没遇到什么问题，真就两行指令搞定那种。

### 编写 whisper 的 gradio 页面

你说得对但是 whisper 是能直接通过命令行来调用的啊，这里选择用 gradio 做个 webui。

然后我其实也没细学 gradio 的文档啊，可能会有一些错误解释，我就按照自己的理解来了。

我的代码 be like ↓

```python
import gradio as gr
import whisper

import json

possi_langs = [
    "Chinese",
    # 在这里填充其他可用的语种，我直接把 whisper 帮助里支持的语种全粘进去了
    # 这里为了文档短点就先这样
]

# 供 gradio 调用的函数
def conv(from_file, model="base", lang="Chinese"):
    # 加载模型
    model = whisper.load_model(model)
    # 启动转换
    result = model.transcribe(
        from_file,
        language=lang,
    )
    # 返回文本化的结果
    return json.dumps(result, ensure_ascii=False, indent=4)

# gradio 的接口
demo = gr.Interface(
    # 填入上面定义的函数
    fn=conv,
    # 填入函数对应的三个参数来源
    inputs=[
        # 第一个参数：音频文件路径，这里使用 gradio 自带的 Audio 组件
        gr.Audio(type="filepath"),
        # 第二个参数：使用模型，这里使用下拉框从 whisper 的可用模型里选
        gr.Dropdown(whisper.available_models(), value="base", type="value"),
        # 第三个参数：输入语言
        # 找了一圈似乎没有办法从程序里得到 whisper 的支持语种，于是在上面自己定义了一个可用的列表
        gr.Dropdown(possi_langs, value="Chinese", type="value"),
    ],
    # 填入函数的返回值输出到的地方，这里是一个文本框
    outputs=gr.Text(),
)

demo.launch()
```

在 vscode 里直接点开始调试就可以运行了，然后访问终端输出的那段地址就行

（如果直接在浏览器里输地址记得加上 `http://` 不然它给你报一堆 ssl 错误）

如果想要在不打开 vscode 的情况下启动，则可以在激活虚拟环境后使用 `python <你的gradio程序>.py` 来启动，或者直接指定虚拟环境中的那个解释器的路径：`.\.venv\Scripts\python.exe <你的gradio程序>.py`

emm 就是这样，感谢你看到这里 w
