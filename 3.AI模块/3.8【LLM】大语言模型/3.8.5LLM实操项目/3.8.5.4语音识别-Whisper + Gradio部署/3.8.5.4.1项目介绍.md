# 自动语音识别的基本原理

## 简介
NLP全称Natural Language Processing，即自然语言处理。

主要应用有信息提取、文本生成、智能问答、机器翻译、文本挖掘、知识图谱、自动语音识别

本项目用到的其中一个

自动语音识别：

大致步骤：语音输入->音频信号特征提取->声学模型处理->语言模型处理

## 自动语音识别 (ASR) 大致步骤：
### 1. 语音输入
- 实时采集：通过计算机或其他设备上的麦克风捕获来自用户的真实语音信号。
- 文件读取：从预先录制并存储为标准音频格式（如.wav、.mp3）的文件中加载语音数据。
### 2.音频信号特征提取
**第一步：加窗分帧**

- 分帧：将连续的音频流分割成一系列短时间片段（帧），通常帧长设置在15毫秒至30毫秒之间，以适应语音信号瞬态特性及处理效率需求。
- 帧移：为了避免因分帧导致的语音信息断裂，相邻帧之间保持一定的重叠（如帧长的50%），确保连续性。
- 加窗：在每个帧的原始信号上应用窗函数（如汉明窗、海明窗等），通过乘法操作平滑帧边缘，减少频谱泄漏，使帧更接近周期性信号，提高后续处理的准确性。
- 滤波：对加窗后的帧进行预处理，如去除噪声、降噪、带通滤波等，以增强语音特征的突出性，减轻无关信号对识别效果的干扰。

**第二步：声音特征提取**
- 变换：将每个加窗分帧后的音频片段转换为一组特征向量，该向量能够有效表征该帧的语音内容。
  - 常用的声音特征提取方法包括Mel频率倒谱系数(MFCC)、线性预测编码(LPC)、感知线性预测(PLP)等。
  - MFCC：将音频信号从时域转换到Mel频率域，进一步计算其离散余弦变换(DCT)，得到一组反映频谱特性的低维向量，常用于观察序列。
### 3.声学模型+语言模型
#### 概念定义
1. 音素
  - 单词的发音由音素构成。
  - 对于英语，常见的音素集是卡内基梅隆大学提供的包含39个音素的集合。
  - 对于汉字，音素集除了包括声母和韵母外，还需考虑音调，通常采用汉语拼音体系中的元素来构建。
2. 状态
  - 音素的进一步细化：通常将一个音素划分为3个状态，以更精确地描述其发音过程中的动态变化。
#### 声学模型工作流程
- 输入：将第二步中提取的帧对应的特征向量作为输入。
- 输出：输出为音素信息。
#### 声学模型特性与训练
- 识别能力：经过大量资料训练的声学模型能够识别每一帧，并将其转化为最可能的状态。
- 记忆能力：为解决相邻帧状态差异较大但实际上应相近的问题，采用具有记忆能力的模型，如DNN+HMM、RNN+LSTM，能够在将当前帧转化为状态时考虑到上一帧的状态。
#### 状态到音素的转化
- 考虑相邻音素影响：正常发音时，相邻音素间存在读音影响。因此，在输出时通常考虑当前音素及其左右邻近音素（左边、自身、右边）。
- 决策树应用：采用决策树等方法将状态转化为音素。
#### 语言模型与解码
- 文本转化：通过声学模型获取大量音素后，利用语言模型将其转化为文本。
- 语言模型构建：语言模型经过大量训练，能够搭建一个描述词汇间上下文依赖关系的状态网络。
- 解码过程：根据已知音素，通过搜索状态网络找到概率最大的路径，从而得出文本。
- 声学模型与语言模型的关系：二者共同构成解码过程，即声音模型+语音模型=解码。
