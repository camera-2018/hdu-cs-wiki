# SD基础使用教程
> 参考文档：[零基础安装攻略](https://nenly.notion.site/c5805e7ae26b4683a277c5586ea05904#e56d8abbd00540c4be69792908fb1a48)/[官方文档](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
## 1.硬件要求
  - 最低配置
    - RTX2060及同等性能显卡
    - 显存6G，内存8G
    - 硬盘空间20G
  - 推荐配置
    - RTX3060Ti及同等性能显卡
    - 显存8G，内存16G
    - 100-150G硬盘空间
  
倘若你对于自己的硬件性能非常自信，那么你可以对照着本篇顶部的参考文档来进行本地部署，当然了，下面的文档也会对你的部署有所帮助，只不过是为了在云服务器上部署而稍微多了几个步骤而已。

::: tip **🤔我的笔记本可是RTX4060，是不是比3060Ti厉害很多？**
笔记本4060，即NVIDIA GeForce RTX 4060 Laptap，性能基本相当于台式机RTX3060，跑应该是能跑的（我没试过），但我仍然建议你在云服务器上部署它，一方面可以获得更好的性能，出图更加舒服，并且8G显存16G内存的要求对于一般的游戏本来说也是很危险的，稍微一个不小心就会爆显存；一方面部署SD涉及到一系列的环境安装，要是出了什么问题重新开一台服务器就好了。
:::

## 2.搭建过程
我们的目标是在趋动云上部署我们的Stable Diffusion WebUI 1.7
::: warning 修改警告
部署教程已过时，想要进行部署的同学可以使用AutoDL进行一键部署，简单方便。
:::

## 3.更精准的描述：简单的参数/提示词（Prompt）使用手册
### Step1：基本使用
- 让我们先来大致的了解一下WebUI的界面
> 如果你对英文不太熟悉，我强烈建议你先到插件安装学习安装一个中文插件

> 记住！大模型不认识中文，即便安装了中文插件，提示词的输入也只能使用全英文

![图片](https://cdn.xyxsw.site/c3548f8f-3055-419a-8a48-b051cf532eb5.jpg)

- 理论上，你只要填入提示词点击生成，就可以画出你想要的图片，然而现实很骨感，画出来的图总是不尽人意，比如说下面这张（胆小慎入，想看可以翻开）：

::: details 胆小慎入，想看可以翻开
输入提示词：一个女孩，学生，青少年，美丽（美丽你个头啊，大辟谷效应犯了）
![图片](https://cdn.xyxsw.site/a84c393b-9e88-4552-8598-203d680c3aab.png)
:::

- 为什么我画出来的图和我想象中的模样差距这么大？可能是你的提示词使用不到位！提示词是Stable Diffusdion的灵魂，他是你与模型沟通最重要的渠道之一，只有写出让机器完全理解你的提示词，才能绘画出你心中所想的图片。下面我们来介绍一下Prompt的使用技巧。

### Step2：Prompt技巧
提示词分为正面提示词和负面提示词，这两种提示词同等重要，两者都不可忽略！
1. 正面提示词
    - 人物主体特征：服饰穿搭/发型发色/五官特点/面部表情/肢体动作
    - 场景特征：显著影响场景/大场景/小细节/白天黑夜/
    - 视角：镜头距离/人物比例/观察视角
    - 画质：best quelity/ultra-detailed（高分辨率/高质量等提示词）
    - 画风：二次元（anime）/真实（realistic）

2. 负面提示词
- 负面提示词包括的部分很多，不仅可以让你去除不想要的画面细节，还可以避免AI画出一些不是人的东西（欢乐谷效应犯了）例如AI绘画常出现的多人/多手/多脚/肢体漂浮/人物畸形等等等等，我这里先给大家一套我自己常用的超长吟唱魔法，可以应对大部分画面出错的问题，我想应该可以对你有些帮助。
::: info 常用负面提示词
Multiple people,long neck,acnes,missing limb,deformed,mutated,malformed limbs,mutation,bad body,long body,(fat:1.2),skin spots,skin blemishes,disfigured,ugly,fused fingers,too many fingers,extra legs,bad feet,cross-eyed,mutated hands,poorly drawn hands,malformed hands,floating limbs,mutated hands and fingers,disconnected limbs,poorly drawn face,bad hands,missing fingers,extra arms,extra limb,blurry,low quality,monochrome,username,out of focus,grayscale,worstquality,signature,watermark,bad anatomy,sketches,lowres,bad proportions,cropped,

如果你有兴趣的话，可以把这段咒语放进翻译软件里，看看这段咒语到底在说啥
:::

- 接下来让我们用详细的prompt再来画一张图片试试看，效果就会好很多啦（至少像个人了）
![图片](https://cdn.xyxsw.site/ac44f948-75aa-49dc-be38-85f5c0c8203a.png)
  
## 4.更多样的风格：更换模型
### Step1：寻找模型
为什么我的图片画出来的效果那么烂？可能是底模（基底模型）不太好！我们默认使用的是官方的预训练模型v1-5-pruned-emaonly，它生成的图片比较基础，很多地方也不太细致。
- 我们可以去一些网站找找我们喜欢的模型，例如Civita或者Huggingface
![图片](https://cdn.xyxsw.site/97f7cea9-3a88-4a59-b5a8-f5feb5cb2319.png)
> 这里有数不清的模型供你选择！你可以选择一个你喜欢的模型，然后进入下载。

![图片](https://cdn.xyxsw.site/fe92d1ec-ed1b-4ed3-bbd2-fe73491c6c02.png)
> 图为Stable Diffusion使用counterfeit V2.5模板生成图片

::: tip **🤔模型太多了，有什么推荐的模型让我使用吗？**
模型根据使用场景，一般可以分为动画类（anime）和现实类
  - 动画类的模型anythingV5和counterfeit V2.5是比较常用的anime模型，一般用于生成可爱的二次元图片，本人也经常用counterfeit在出图，如果你对二次元很感兴趣，这两个可以拿来入手
  - 现实类的模型门类比较复杂，Deliberate模型用于生成现实的人像，Realistic Vision V6.0 B1专注于真实的场景和人物，Product Design适合生成3D感十足的简单物体，根据需要在网络上寻找你需要的模型！
:::

### Step2：下载模型
在Civita中，下载模型非常方便，因为你甚至不需要注册账号（但可能需要一些其他东西）！（魔搭社区也有快速体验版）

- 进入你想下载的模型界面，点击下载键，这个后缀safetensor的文件就是模型啦！
![图片](https://cdn.xyxsw.site/2dd309e5-32f8-4a8f-b9e9-06f6c1e1d9d5.png)

- 这样就下载好了！如果你在HuggingFace里下载模型，就只要下载后缀safetensor的文件即可，如果有vae.pt也一并下载
![图片](https://cdn.xyxsw.site/238e12dd-c389-4965-86af-baa64e9e6aa5.png)

::: tip **🤔VAE是什么？VAE在哪里使用？**
  - VAE，全名 Variational autoenconder，中文叫变分自编码器。作用差不多可以理解为滤镜。 在生成 AI 绘画时，会对输出的颜色和线条产生影响。简单来说，vae可以让你的图片生成线条更加清晰，画面更加明亮，模型和它搭配使用效果更佳
  - `Setting - User Interface - Quicksettings list`中加入`sd_vae`,点击Apply，再点击Reload，就会发现model的旁边新出现了vae的选择框了。
:::

### Step3：安装模型
**1. 普通上传**
- 找到趋动云服务器的JupyterLab，在左侧找到文件夹gemini/code/stable-diffusion-webui/models/Stable-Diffusion，你会发现里面还有一个v1-5-pruned-emaonly.safetensors这就是官方模型，我们将刚下载的模型拖入文件夹目录中
![图片](https://cdn.xyxsw.site/f972ba74-8f91-4bbd-86b5-73361946c4c7.png)

**2. SSH上传**
- 这个方法的目的是加快模型的上传速度，在Web中文件的上传速度还是有所限制，我们可以打开趋动云的SSH功能，通过SSH我们的文件可以上传的更快
![图片](https://cdn.xyxsw.site/9a784fda-861f-40bb-bd07-a0e2e234f759.png)

- 在这里，你可以选择用你自己的电脑终端或者使用VScode/terminus之类的软件来连接服务器

### Step4：使用模型
- 当你安装好模型之后，回到webUI界面，再点击左上角的模型选项，你会发现你的模型已经加载进去了。现在，你可以自由的使用这个模型来进行出图了！

## 5.更方便的使用：插件安装
### Step1：安装教程
Stable-Diffusion拥有大量便捷的插件，可以实现由小到大的各个功能！

如果你要安装插件，首先你要退出正在运行的Webui，然后用下面的命令再启动一次

`python launch.py --share --listen --enable-insecure-extension-access`

这个时候就可以在webui中下载插件了！

- 点击Extension-Install from URL，输入插件的Git网址，点击Install，就可以安装了！我们先来装一个中文插件，在`URL for extension's git repository`中输入：
    - `https://gitcode.net/overbill1683/stable-diffusion-webui-localization-zh_Hans.git`
![图片](https://cdn.xyxsw.site/d798d2b7-004d-4ba4-b2fa-386082dabce5.png)

- 我们回到Installed，发现多了一个插件，这就是我们新安装的插件！
![图片](https://cdn.xyxsw.site/eb6818ce-63a0-47d8-b853-4952fc91e77b.png)

- 现在我们来到Setting-User Interface-Localization，来设置我们新安装的中文插件，点击Apply setting，再点击Reload UI，你的界面就变成中文的了！
![图片](https://cdn.xyxsw.site/aa73b0f4-960e-437f-970f-c03ae665ffcf.png)

![图片](https://cdn.xyxsw.site/0d3b6414-9408-4f86-a238-029228c3699c.png)

### Step2：插件推荐
1. oldsix：超好用的提示词插件！作为一个sd新手，对于提示词的使用会很没有方向，oldsix作为一个全中文插件，提供了大量常见提示词，也就是说，你只要在webui里点点点，挑选你心仪的提示词，就可以创造出你想要的画！
> URL：https://github.com/thisjam/sd-webui-oldsix-prompt.git

![图片](https://cdn.xyxsw.site/23518ea6-b79d-4529-bd84-e5232c956271.png)

2. Prompt-all-in one：提示词补全插件，输入前几个字母就能补全你想输入的提示词
> URL：https://github.com/Physton/sd-webui-prompt-all-in-one.git

3. tagger：标签反推插件，炼模型会用到
4. WD1.4：打标插件，炼模型会用到

::: warning **常见问题**
如果你在安装插件过程中遇到128报错，那么大概率是网络出现了一些问题！你可以在终端里（stable-diffusion-webui文件夹下），输入下面的代码的方法来安装插件

`git clone "https://gitclone.com//github.com/Physton/sd-webui-prompt-all-in-one.git" extensions/sd-webui-prompt-all-in-one`

双引号是你要下载插件的URL，后面是下载到本地的路径（extensions/你想取插件文件夹名字，一般取URL最后一节）

git到本地以后重启webui，插件就安装上了！
：：：
