# ResNet
::: warning ğŸ•¶
æ®‹å·®ç¥ç»ç½‘ç»œ(ResNet)æ˜¯ç”±å¾®è½¯ç ”ç©¶é™¢çš„ä½•æºæ˜å¤§ç¥å›¢é˜Ÿæå‡ºçš„ä¸€ä¸ªç»å…¸ç½‘ç»œæ¨¡å‹ï¼Œä¸€ç»ç°ä¸–å°±æˆä¸ºäº†æ²¿ç”¨è‡³ä»Šçš„è¶…çº§ Backboneã€‚
:::
[çŸ¥ä¹](https://zhuanlan.zhihu.com/p/101332297)

[è®ºæ–‡](https://arxiv.org/pdf/1512.03385.pdf)

## WHY residual?
::: warning ğŸ¨
åœ¨ ResNet æå‡ºä¹‹å‰ï¼Œæ‰€æœ‰çš„ç¥ç»ç½‘ç»œéƒ½æ˜¯é€šè¿‡å·ç§¯å±‚å’Œæ± åŒ–å±‚çš„å åŠ ç»„æˆçš„ã€‚
äººä»¬è®¤ä¸ºå·ç§¯å±‚å’Œæ± åŒ–å±‚çš„å±‚æ•°è¶Šå¤šï¼Œè·å–åˆ°çš„å›¾ç‰‡ç‰¹å¾ä¿¡æ¯è¶Šå…¨ï¼Œå­¦ä¹ æ•ˆæœä¹Ÿå°±è¶Šå¥½ã€‚ä½†æ˜¯åœ¨å®é™…çš„è¯•éªŒä¸­å‘ç°ï¼Œéšç€å·ç§¯å±‚å’Œæ± åŒ–å±‚çš„å åŠ ï¼Œä¸ä½†æ²¡æœ‰å‡ºç°å­¦ä¹ æ•ˆæœè¶Šæ¥è¶Šå¥½çš„æƒ…å†µï¼Œåè€Œå‡ºç°ä¸¤ç§é—®é¢˜ï¼š

- æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸

æ¢¯åº¦æ¶ˆå¤±ï¼šè‹¥æ¯ä¸€å±‚çš„æ¢¯åº¦è¯¯å·®å°äº 1ï¼Œåå‘ä¼ æ’­æ—¶ï¼Œç½‘ç»œè¶Šæ·±ï¼Œæ¢¯åº¦è¶Šè¶‹è¿‘äº 0

æ¢¯åº¦çˆ†ç‚¸ï¼šè‹¥æ¯ä¸€å±‚çš„æ¢¯åº¦è¯¯å·®å¤§äº 1ï¼Œåå‘ä¼ æ’­æ—¶ï¼Œç½‘ç»œè¶Šæ·±ï¼Œæ¢¯åº¦è¶Šè¶‹è¿‘äºæ— ç©·å¤§

- é€€åŒ–ç°è±¡

å¦‚å›¾æ‰€ç¤ºï¼Œéšç€å±‚æ•°è¶Šæ¥è¶Šæ·±ï¼Œé¢„æµ‹çš„æ•ˆæœåè€Œè¶Šæ¥è¶Šå·®(error è¶Šå¤§)
:::
![](https://cdn.xyxsw.site/boxcnBDfBnOPmS0btwNseKvsN6f.png)

## ç½‘ç»œæ¨¡å‹

![](https://cdn.xyxsw.site/boxcnn8a16DYyEPEVuHxvvw7eAf.png)

::: warning ğŸ˜º
æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒResNet çš„ç½‘ç»œä¾æ—§éå¸¸æ·±ï¼Œè¿™æ˜¯å› ä¸ºç ”ç©¶å›¢é˜Ÿä¸ä»…å‘ç°äº†é€€åŒ–ç°è±¡ï¼Œè¿˜é‡‡ç”¨å‡ºä¸€ä¸ªå¯ä»¥å°†ç½‘ç»œç»§ç»­åŠ æ·±çš„ trickï¼šshortcutï¼Œäº¦å³æˆ‘ä»¬æ‰€è¯´çš„ residualã€‚

- ä¸ºäº†è§£å†³æ¢¯åº¦æ¶ˆå¤±æˆ–æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼ŒResNet è®ºæ–‡æå‡ºé€šè¿‡æ•°æ®çš„é¢„å¤„ç†ä»¥åŠåœ¨ç½‘ç»œä¸­ä½¿ç”¨ BNï¼ˆBatch Normalizationï¼‰å±‚æ¥è§£å†³ã€‚
- ä¸ºäº†è§£å†³æ·±å±‚ç½‘ç»œä¸­çš„é€€åŒ–é—®é¢˜ï¼Œå¯ä»¥äººä¸ºåœ°è®©ç¥ç»ç½‘ç»œæŸäº›å±‚è·³è¿‡ä¸‹ä¸€å±‚ç¥ç»å…ƒçš„è¿æ¥ï¼Œéš”å±‚ç›¸è¿ï¼Œå¼±åŒ–æ¯å±‚ä¹‹é—´çš„å¼ºè”ç³»ã€‚è¿™ç§ç¥ç»ç½‘ç»œè¢«ç§°ä¸º æ®‹å·®ç½‘ç»œ (ResNets)ã€‚ResNet è®ºæ–‡æå‡ºäº† residual ç»“æ„ï¼ˆæ®‹å·®ç»“æ„ï¼‰æ¥å‡è½»é€€åŒ–é—®é¢˜ã€‚
:::
### residual ç»“æ„

![](https://cdn.xyxsw.site/boxcnhgVaLChu3O2omGJKzFU7uB.png)

## ç½‘ç»œä»£ç 

```python
import torch.nn as nn
import torch


# ResNet18/34çš„æ®‹å·®ç»“æ„ï¼Œç”¨çš„æ˜¯2ä¸ª3x3çš„å·ç§¯
class BasicBlock(nn.Module):
    expansion = 1  # æ®‹å·®ç»“æ„ä¸­ï¼Œä¸»åˆ†æ”¯çš„å·ç§¯æ ¸ä¸ªæ•°æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼Œä¸å˜åˆ™ä¸º1

    def __init__(self, in_channel, out_channel, stride=1, downsample=None):  # downsampleå¯¹åº”è™šçº¿æ®‹å·®ç»“æ„
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,
                               kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channel)
        self.relu = nn.ReLU()
        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,
                               kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channel)
        self.downsample = downsample

    def forward(self, x):
        identity = x
        if self.downsample is not None:  # è™šçº¿æ®‹å·®ç»“æ„ï¼Œéœ€è¦ä¸‹é‡‡æ ·
            identity = self.downsample(x)  # æ·å¾„åˆ†æ”¯ short cut

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        out += identity
        out = self.relu(out)

        return out

# ResNet50/101/152çš„æ®‹å·®ç»“æ„ï¼Œç”¨çš„æ˜¯1x1+3x3+1x1çš„å·ç§¯
class Bottleneck(nn.Module):
    expansion = 4  # æ®‹å·®ç»“æ„ä¸­ç¬¬ä¸‰å±‚å·ç§¯æ ¸ä¸ªæ•°æ˜¯ç¬¬ä¸€/äºŒå±‚å·ç§¯æ ¸ä¸ªæ•°çš„4å€

    def __init__(self, in_channel, out_channel, stride=1, downsample=None):
        super(Bottleneck, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel,
                               kernel_size=1, stride=1, bias=False)  # squeeze channels
        self.bn1 = nn.BatchNorm2d(out_channel)
        # -----------------------------------------
        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel,
                               kernel_size=3, stride=stride, bias=False, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channel)
        # -----------------------------------------
        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel * self.expansion,
                               kernel_size=1, stride=1, bias=False)  # unsqueeze channels
        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample

    def forward(self, x):
        identity = x
        if self.downsample is not None:
            identity = self.downsample(x)  # æ·å¾„åˆ†æ”¯ short cut

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    # block = BasicBlock or Bottleneck
    # block_numä¸ºæ®‹å·®ç»“æ„ä¸­conv2_x~conv5_xä¸­æ®‹å·®å—ä¸ªæ•°ï¼Œæ˜¯ä¸€ä¸ªåˆ—è¡¨
    def __init__(self, block, blocks_num, num_classes=1000, include_top=True):
        super(ResNet, self).__init__()
        self.include_top = include_top
        self.in_channel = 64

        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2,
                               padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(self.in_channel)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, blocks_num[0])             # conv2_x
        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)  # conv3_x
        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)  # conv4_x
        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)  # conv5_x
        if self.include_top:
            self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # output size = (1, 1)
            self.fc = nn.Linear(512 * block.expansion, num_classes)

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')

    # channelä¸ºæ®‹å·®ç»“æ„ä¸­ç¬¬ä¸€å±‚å·ç§¯æ ¸ä¸ªæ•°
    def _make_layer(self, block, channel, block_num, stride=1):
        downsample = None

        # ResNet50/101/152çš„æ®‹å·®ç»“æ„ï¼Œblock.expansion=4
        if stride != 1 or self.in_channel != channel * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(channel * block.expansion))

        layers = []
        layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride))
        self.in_channel = channel * block.expansion

        for _ in range(1, block_num):
            layers.append(block(self.in_channel, channel))

        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        if self.include_top:
            x = self.avgpool(x)
            x = torch.flatten(x, 1)
            x = self.fc(x)

        return x


def resnet34(num_classes=1000, include_top=True):
    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes, include_top=include_top)


def resnet101(num_classes=1000, include_top=True):
    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes, include_top=include_top)


'''
æˆ‘ä»¬å¸Œæœ›ä½ èƒ½å¤Ÿå»å°†è®ºæ–‡ä¸‹è½½ä¸‹æ¥ä»¥åè·Ÿä¸€äº›è®²è§£è§†é¢‘å°è¯•å°†è®ºæ–‡ä¸ä»£ç ç»“åˆèµ·æ¥ç†è§£
çœ‹è®ºæ–‡çš„æºç æ˜¯æˆ‘ä»¬å¿…é¡»è¦åšçš„ä¸€ä¸ªä¸­é‡è¦çš„å·¥ä½œ
'''
```

## è§†é¢‘

<Bilibili bvid='BV1P3411y7nn'/>

## æ€è€ƒ

### æ€è€ƒ 1
::: warning ğŸ¤”
è¯·ä½ è‡ªè¡Œäº†è§£ç½‘ç»œç»“æ„ä¸­çš„ BNï¼ˆBatch Normalizationï¼‰å±‚ï¼Œè¿™æ˜¯å¾ˆé‡è¦çš„ä¸€ä¸ª normalization æ“ä½œï¼Œå¦‚æœæ„Ÿå…´è¶£è¿˜å¯ä»¥ç»§ç»­äº†è§£ LN (Layer Normalization)
:::
### æ€è€ƒ 2
::: warning ğŸ¤”
ä½ è§‰å¾—è®ºæ–‡ä¸­æå‡ºç”¨ residual è¿™ä¸€è§£å†³æ–¹æ³•æ¥è§£å†³ç½‘ç»œçš„é€€åŒ–ç°è±¡çš„ä¾æ®æ˜¯ä»€ä¹ˆï¼Œå¦‚æœå¯ä»¥ï¼Œè¯·ä½ è¿›ä¸€æ­¥å°è¯•ç”¨æ•°å­¦è§’åº¦æ€è€ƒè¿™ä¸€é—®é¢˜
:::